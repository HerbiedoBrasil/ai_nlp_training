{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['', 'locals()'],\n",
       " '_oh': {},\n",
       " '_dh': ['C:\\\\Users\\\\herbi\\\\Google Drive\\\\Current_NLP_Bootcamp\\\\nlp_hw_notes'],\n",
       " 'In': ['', 'locals()'],\n",
       " 'Out': {},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x000002EAC8E476D8>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x2eac99a6898>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x2eac99a6898>,\n",
       " '_': '',\n",
       " '__': '',\n",
       " '___': '',\n",
       " '_i': '',\n",
       " '_ii': '',\n",
       " '_iii': '',\n",
       " '_i1': 'locals()'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments for Week-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, we learnt what's the search problem and what's the machine leanring. In this assignment, we need you do some more practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Re-code the house price machine learning\n",
    "\n",
    "###### 1. Random Choose Method to get optimal *k* and *b*\n",
    "###### 2.Supervised Direction to get optimal *k* and *b*\n",
    "###### 3.Gradient Descent to get optimal *k* and *b*\n",
    "###### 4. Try different Loss function and learning rate. \n",
    "\n",
    "For example, you can change the loss function: $Loss = \\frac{1}{n} sum({y_i - \\hat{y_i}})^2$ to $Loss = \\frac{1}{n} sum(|{y_i - \\hat{y_i}}|)$\n",
    "\n",
    "And you can change the learning rate and observe the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### note: pay attention to the differences between X[ï¼š,5] and X[:5] , one refers to an array(5th column), another is a slice of the matrix(first 5 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def draw_rm_and_price():\n",
    "    plt.scatter(X[:, 5], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_rm_and_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price(rm, k, b):\n",
    "    \"\"\"f(x) = k * x + b\"\"\"\n",
    "    return k * rm + b  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, try some random number as parameters k and b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_rm = X[:, 5] # number of rooms \n",
    "k = random.randint(-100, 100) \n",
    "b = random.randint(-100, 100)\n",
    "price_by_random_k_and_b = [price(r, k, b) for r in X_rm]\n",
    "\n",
    "draw_rm_and_price()\n",
    "plt.scatter(X_rm, price_by_random_k_and_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss functions \n",
    "\n",
    "$$ loss = \\frac{1}{n} \\sum{(y_i - \\hat{y_i})^2}$$\n",
    "\n",
    "$$ loss = \\frac{1}{n} \\sum{ (\\mid y_i - \\hat{y_i} \\mid) }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_hat): # to evaluate the performance \n",
    "    return sum((y_i - y_hat_i)**2 for y_i, y_hat_i in zip(list(y), list(y_hat))) / len(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_abs(y,y_hat):\n",
    "    return sum(abs(y_i - y_hat_i) for y_i, y_hat_i in zip(list(y), list(y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['feature_names']\n",
    "#data['DESCR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whenever a new loss is smaller than the current best, adjust the next parameters on a random direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trying_times = 100\n",
    "\n",
    "min_loss = float('inf')\n",
    "\n",
    "best_k = random.random() * 200 - 100\n",
    "best_b = random.random() * 200 - 100\n",
    "\n",
    "direction = [\n",
    "    (+1, -1),  # first element: k's change direction, second element: b's change direction\n",
    "    (+1, +1), \n",
    "    (-1, -1), \n",
    "    (-1, +1),\n",
    "]\n",
    "\n",
    "next_direction = random.choice(direction)\n",
    "\n",
    "scalar = 0.1\n",
    "\n",
    "for i in range(trying_times):\n",
    "    \n",
    "    k_direction, b_direction = next_direction\n",
    "    \n",
    "    current_k, current_b = best_k + k_direction * scalar, best_b + b_direction * scalar\n",
    "    \n",
    "    price_by_k_and_b = [price(r, current_k, current_b) for r in X_rm]\n",
    "\n",
    "    current_loss = loss(y, price_by_k_and_b)\n",
    "    \n",
    "    if current_loss < min_loss: # performance became better\n",
    "        min_loss = current_loss\n",
    "        best_k, best_b = current_k, current_b\n",
    "        \n",
    "        next_direction = next_direction\n",
    "        print('When time is : {}, get best_k: {} best_b: {}, and the loss is: {}'.format(i, best_k, best_b, min_loss))\n",
    "    else:\n",
    "        next_direction = random.choice(direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(X, y, k, b, learning_rate):\n",
    "  #  weight_deriv = 0\n",
    "    k_deriv=0\n",
    "   # bias_deriv = 0\n",
    "    b_deriv=0\n",
    "    N = len(X)\n",
    "    \n",
    "    #learning rate \n",
    "  \n",
    "\n",
    "    for i in range(N):\n",
    "        # Calculate partial derivatives\n",
    "        # -2x(y - (mx + b))\n",
    "        k_deriv = -2*X[i] * (y[i] - (k*X[i] + b))\n",
    "\n",
    "        # -2(y - (mx + b))\n",
    "        b_deriv = -2*(y[i] - (k*X[i] + b))\n",
    "\n",
    "    # We subtract because the derivatives point in direction of steepest ascent\n",
    "    k -= (k_deriv / N) * learning_rate\n",
    "    b -= (b_deriv / N) * learning_rate\n",
    "\n",
    "    return k, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_weights(X_rm, y,10.054955982213443, -4.06270750988142, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cost_history = []\n",
    "loss_history = [] \n",
    "iters=100000\n",
    "alpha=0.01\n",
    "X_rm = X[:, 5] # number of rooms \n",
    "N=len(X_rm)\n",
    "theta=11,-49\n",
    "for i in range(iters):\n",
    "    #print(current_k)\n",
    "    price_by_k_and_b = [price(r, theta[0], theta[1]) for r in X_rm]\n",
    "    #current_loss_array = price_by_k_and_b - y\n",
    "    current_loss=loss(y,price_by_k_and_b)\n",
    "    theta=update_weights(X_rm,y,theta[0],theta[1],alpha)\n",
    "    #update_weights(X, y, k, b, learning_rate):\n",
    "   \n",
    "\n",
    "        # Log Progress\n",
    "    if i % 100 == 0:\n",
    "        print(theta)\n",
    "        print(current_loss)\n",
    "            #print(\"iter={:d}    weight={:.2f}    bias={:.4f}    cost={:.2}\".format(i, current_k, current_b, current_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
