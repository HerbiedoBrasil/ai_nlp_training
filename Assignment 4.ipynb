{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-04 基于维基百科的词向量构建¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step -01 Download the Wikipedia Chinese Corpus \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step-02: Using https://github.com/attardi/wikiextractor to extract the wikipedia corpus\n",
    "第二步：使用python wikipedia extractor抽取维基百科的内容\n",
    "\n",
    "用 wikiextractor.py 对内容进行抽取，得到wiki.txt\n",
    "\n",
    "然后将文本里的繁体都转换为简体，使用opencc，需要安装opencc (https://github.com/yichen0831/opencc-python ) \n",
    "\n",
    "提取文本里的中文，去除英文内容，并且进行分词处理，得到wiki_only_simple_and_cut.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import sys\n",
    "#from gensim.corpora import WikiCorpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\herbi\\\\Google Drive\\\\Current_NLP_Bootcamp\\\\nlp_hw_notes'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_wiki_dump = \"C:\\\\Users\\\\herbi\\\\Documents\\\\nlp_camp_local\\\\zhwiki-20190720-pages-articles-multistream.xml.bz2\"\n",
    "path_to_wiki_folder=\"C:\\\\Users\\\\herbi\\\\Documents\\\\nlp_camp_local\"\n",
    "wiki_dump=\"zhwiki-20190720-pages-articles-multistream.xml.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(path_to_wiki_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\herbi\\\\Documents\\\\nlp_camp_local'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use WikiExtractor.py to extract all the wiki articles \n",
    "https://github.com/attardi/wikiextractor/wiki#Usage \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python   WikiExtractor.py   zhwiki-20190720-pages-articles-multistream.xml.bz2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jieba\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from opencc import OpenCC\n",
    "import os\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "zhwiki = Path('C:\\\\Users\\\\herbi\\\\Documents\\\\nlp_camp_local\\\\text_v0\\\\AA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trad2sim(input_dir, output_dir):\n",
    "    output_dir = input_dir.parent / output_dir\n",
    "    if not output_dir.exists(): output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for wiki in tqdm(input_dir.iterdir()):\n",
    "        os.system('python -m opencc -c t2s -i {wiki} -o {output}'.format(\n",
    "            wiki=str(wiki), output=str(output_dir/('simplified_'+wiki.name))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [02:21,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "trad2sim(zhwiki,'simplified_zhwiki')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### note: tqdm : https://github.com/tqdm/tqdm \n",
    "Progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_set='的'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_zhwiki = zhwiki.parent / 'simplified_zhwiki'\n",
    "simplified_zhwiki.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_texts(simplified_zhwiki):\n",
    "    texts = []\n",
    "    for wiki in tqdm(simplified_zhwiki.iterdir()):\n",
    "        with wiki.open(encoding='utf8') as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "                if line == '' or line.startswith('<doc') or line.startswith('</doc'): continue\n",
    "                words = []\n",
    "                for word in jieba.cut(line):\n",
    "                    if word in stop_words_set: continue\n",
    "                    words.append(word)\n",
    "                if len(words) > 1: texts.append(words.copy())\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\herbi\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.691 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "100it [04:41,  3.27s/it]\n"
     ]
    }
   ],
   "source": [
    "texts = generate_texts(simplified_zhwiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283210"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.pickle', 'wb') as f:\n",
    "    pickle.dump(texts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\herbi\\\\Documents\\\\nlp_camp_local'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec\n",
    "Step-03: Using gensim get word vectors:\n",
    "Reference:\n",
    "\n",
    "https://radimrehurek.com/gensim/models/word2vec.html\n",
    "https://www.kaggle.com/jeffd23/visualizing-word-vectors-with-t-sne\n",
    "第三步：参考Gensim的文档和Kaggle的参考文档，获得词向量。 注意，你要使用Jieba分词把维基百科的内容切分成一个一个单词，然后存进新的文件中。然后，你需要用Gensim的LineSentence这个类进行文件的读取。\n",
    "\n",
    "训练成词向量Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.pickle', 'rb') as f:\n",
    "    corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283210"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_short=corpus[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sentences=corpus_short, size=300, window=5, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.45744705e-02, -3.01090389e-01,  9.09206793e-02,  3.02521378e-01,\n",
       "        2.42115304e-01, -2.21010357e-01, -7.73816481e-02, -3.28866094e-01,\n",
       "       -1.18302405e-01,  4.72516604e-02, -1.39063746e-01, -5.61035164e-02,\n",
       "       -1.17170028e-01,  2.30280355e-01,  2.14368880e-01,  2.28909150e-01,\n",
       "        3.28356713e-01, -4.09788787e-02,  5.15622133e-03,  2.18565539e-02,\n",
       "        1.65645555e-01, -1.54658034e-01,  2.26505503e-01,  1.95999257e-02,\n",
       "       -8.36538076e-02, -1.32283103e-02, -5.37586436e-02,  1.32813022e-01,\n",
       "       -3.10738951e-01,  3.18564773e-01,  2.38405913e-01, -4.58056480e-01,\n",
       "       -2.33745515e-01, -5.31336516e-02, -1.43277705e-01,  2.43143402e-02,\n",
       "        1.43233031e-01,  2.67610699e-01, -1.73286796e-01, -2.43222862e-01,\n",
       "       -5.74793033e-02, -1.39925167e-01, -2.95943078e-02,  4.18826938e-01,\n",
       "        1.21859647e-01,  3.40619832e-01, -1.50585413e-01, -2.43832678e-01,\n",
       "        1.30350798e-01, -2.12694302e-01,  6.81144446e-02, -2.55437553e-01,\n",
       "        2.36266986e-01, -1.34301171e-01,  4.75058444e-02,  1.14699341e-01,\n",
       "       -3.08147259e-02,  3.10507208e-01, -8.45678821e-02, -1.83317512e-01,\n",
       "       -2.64224466e-02, -2.27934793e-01, -5.09764104e-05,  4.05372530e-02,\n",
       "       -7.86961168e-02,  3.10613424e-01,  3.52976918e-02, -8.39349031e-02,\n",
       "       -1.60760388e-01, -1.53562456e-01, -2.82307565e-02,  1.21179633e-01,\n",
       "       -2.66083002e-01,  1.12228006e-01, -2.21606921e-02,  1.51582435e-01,\n",
       "       -3.79735410e-01, -6.66911304e-02,  4.84343655e-02,  2.76157865e-03,\n",
       "       -2.19090909e-01, -1.11125037e-01, -1.21320836e-01, -1.86979815e-01,\n",
       "        2.04416271e-03, -1.87569067e-01, -6.32888898e-02,  2.68521547e-01,\n",
       "       -1.69357881e-01,  3.19599241e-01,  3.75793129e-03,  5.28556742e-02,\n",
       "        2.90548593e-01, -2.87281964e-02,  9.73788425e-02,  5.01036271e-02,\n",
       "        2.38715664e-01,  1.95741821e-02,  1.17359739e-02,  3.43360193e-03,\n",
       "       -3.45039845e-01, -2.85414785e-01, -4.61913310e-02,  1.90897867e-01,\n",
       "       -8.48002508e-02, -1.94252823e-02, -3.98795716e-02, -1.39368430e-01,\n",
       "       -9.31577906e-02,  1.21813558e-01, -1.21117309e-01,  9.05230921e-03,\n",
       "        1.87999472e-01, -6.15382530e-02, -2.94763967e-02, -3.99586082e-01,\n",
       "       -9.82699469e-02,  2.20726281e-01, -2.38102704e-01,  6.45374298e-01,\n",
       "        1.08815581e-01, -4.41279709e-02, -3.66199613e-02, -1.66005511e-02,\n",
       "       -4.90026437e-02,  2.57247686e-01, -3.46955061e-02, -4.02378216e-02,\n",
       "       -2.64623258e-02,  5.65961674e-02, -4.02268581e-02,  9.51666012e-02,\n",
       "        4.99887243e-02,  2.96626911e-02,  7.64782205e-02,  1.00069433e-01,\n",
       "       -8.04244727e-02, -3.32005508e-02,  2.53495842e-01, -1.03531852e-01,\n",
       "       -2.04637542e-01,  2.76002362e-02, -1.52619213e-01, -1.57044679e-02,\n",
       "       -2.71052611e-03,  2.40985274e-01,  7.26145580e-02, -7.62870982e-02,\n",
       "       -6.05504923e-02,  6.46760091e-02,  1.29398704e-01, -2.53543574e-02,\n",
       "        1.49468347e-01, -2.16926888e-01, -2.52499640e-01,  3.87523025e-02,\n",
       "        1.15827769e-01,  2.60847956e-01,  9.98547524e-02, -2.52575073e-02,\n",
       "       -2.46750370e-01,  3.24694463e-03, -5.49311101e-01,  2.93678511e-02,\n",
       "        1.05741918e-01,  6.30976558e-02, -3.66922408e-01, -5.56294108e-03,\n",
       "        4.82117869e-02, -2.28594065e-01, -8.73588324e-02, -3.03951204e-01,\n",
       "        6.56317025e-02, -1.16761424e-01, -6.73701987e-02,  2.15685070e-01,\n",
       "        1.47165939e-01, -2.29677752e-01, -1.67056397e-01,  2.37173244e-01,\n",
       "       -4.72651087e-02, -2.07980484e-01, -2.24727198e-01, -2.40629427e-02,\n",
       "        2.03927815e-01, -4.74477038e-02, -2.12567434e-01, -3.80521342e-02,\n",
       "        2.29985967e-01, -1.21934861e-01, -1.45691991e-01, -2.19855011e-01,\n",
       "        3.32936160e-02, -3.94153893e-02, -3.93033996e-02, -3.19185704e-02,\n",
       "        1.02855407e-01, -4.01253290e-02,  2.76659042e-01, -3.25766742e-01,\n",
       "       -2.69357949e-01, -9.29328725e-02,  1.11035667e-01, -1.91199750e-01,\n",
       "        1.87125325e-01,  3.76226865e-02, -2.04701871e-01, -2.65451670e-01,\n",
       "       -3.22537757e-02,  3.68633345e-02,  4.15796250e-01, -7.45215267e-02,\n",
       "       -1.86944887e-01,  2.23155588e-01, -2.29501165e-02, -4.67027605e-01,\n",
       "       -1.37207985e-01, -1.04357548e-01,  9.21627581e-02, -1.33453369e-01,\n",
       "        3.71902734e-02,  2.68405348e-01, -4.26422395e-02,  8.07227846e-03,\n",
       "        1.86972886e-01,  5.13533093e-02, -2.53728569e-01,  5.54928221e-02,\n",
       "        2.26807922e-01,  7.82837067e-03,  1.46803679e-03,  1.06272995e-01,\n",
       "        1.69563651e-01, -6.76002949e-02, -3.05969566e-01, -5.20693719e-01,\n",
       "       -3.35895456e-02, -4.03389558e-02,  3.98931742e-01, -5.08018553e-01,\n",
       "       -4.24722731e-01,  1.80780873e-01,  1.87785253e-01,  2.55545944e-01,\n",
       "        1.71625435e-01, -4.04304594e-01,  1.56692952e-01, -1.44585013e-01,\n",
       "       -5.61770141e-01, -2.29968593e-01,  1.05733961e-01, -1.68760851e-01,\n",
       "        4.11721766e-02,  1.24154449e-01,  8.75025466e-02, -6.08439110e-02,\n",
       "        2.05500081e-01,  1.93869770e-01, -2.84814149e-01, -2.85463091e-02,\n",
       "        1.23801082e-01,  8.82069468e-02, -1.88927084e-01, -1.30911350e-01,\n",
       "        8.60000104e-02, -2.50756770e-01, -5.29752851e-01, -1.77278444e-02,\n",
       "        5.42429164e-02,  1.24008860e-02, -9.55382064e-02, -1.98655903e-01,\n",
       "        2.47817263e-01, -2.36887977e-01, -2.17245221e-01, -3.36653292e-01,\n",
       "        5.08965412e-03,  2.47760594e-01, -1.77005142e-01,  1.51545759e-02,\n",
       "       -1.36481836e-01,  2.97854364e-01, -8.94697532e-02,  1.82590246e-01,\n",
       "       -7.60666728e-02,  8.89120176e-02,  1.80220723e-01,  1.22810043e-01,\n",
       "        2.74340302e-01,  3.66968006e-01, -5.25722979e-03,  9.68458131e-02,\n",
       "        4.83477145e-01, -4.12708193e-01,  1.83341071e-01,  1.78161263e-02,\n",
       "       -4.98524487e-01, -3.61076444e-02, -1.77231625e-01, -6.33933917e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['数学']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('shortcorpus_word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('新', 0.9998358488082886),\n",
       " ('现实', 0.9996786117553711),\n",
       " ('问题', 0.9995670318603516),\n",
       " ('物理', 0.9995082020759583),\n",
       " ('文明', 0.9994291067123413),\n",
       " ('无', 0.9994125366210938),\n",
       " ('竞争', 0.9993775486946106),\n",
       " ('观点', 0.9993489980697632),\n",
       " ('即使', 0.9993197917938232),\n",
       " ('过程', 0.9992666244506836)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('数学')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007332563400268555"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('数学', '过程')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
